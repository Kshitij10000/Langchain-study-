{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>candidate</th>\n",
       "      <th>location</th>\n",
       "      <th>score</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>Similar Skills</th>\n",
       "      <th>Missing Skills</th>\n",
       "      <th>Preferable Skills</th>\n",
       "      <th>experiences</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NET Technical Team Lead/Engineering Manager</td>\n",
       "      <td>Praveen Tadikemalla</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>60</td>\n",
       "      <td>Praveen Tadikemalla demonstrates a strong tech...</td>\n",
       "      <td>C#, JavaScript, .NET Core, HTML5, Web APIs, De...</td>\n",
       "      <td>Node.js, React, TypeScript, CSS, PostCSS, AppS...</td>\n",
       "      <td>DevOps</td>\n",
       "      <td>Infosys [Technology Lead (15 years)] ,   Wipr...</td>\n",
       "      <td>Naukri_praveentadikemalla[15y_0m].pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          role            candidate  \\\n",
       "0  NET Technical Team Lead/Engineering Manager  Praveen Tadikemalla   \n",
       "\n",
       "        location  score                                     recommendation  \\\n",
       "0  Not specified     60  Praveen Tadikemalla demonstrates a strong tech...   \n",
       "\n",
       "                                      Similar Skills  \\\n",
       "0  C#, JavaScript, .NET Core, HTML5, Web APIs, De...   \n",
       "\n",
       "                                      Missing Skills Preferable Skills  \\\n",
       "0  Node.js, React, TypeScript, CSS, PostCSS, AppS...            DevOps   \n",
       "\n",
       "                                         experiences  \\\n",
       "0   Infosys [Technology Lead (15 years)] ,   Wipr...   \n",
       "\n",
       "                                filename  \n",
       "0  Naukri_praveentadikemalla[15y_0m].pdf  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd \n",
    "\n",
    "load_dotenv()\n",
    "df = pd.read_excel('resumes_report (4).xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"what skills we need for {skill} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skill': 'machine learning',\n",
       " 'text': '1. Strong understanding of mathematics, particularly linear algebra, calculus, and probability theory\\n2. Proficiency in programming languages such as Python, R, or Java\\n3. Knowledge of data manipulation and analysis tools such as Pandas, NumPy, or MATLAB\\n4. Experience with machine learning algorithms and techniques, such as regression, classification, clustering, and neural networks\\n5. Ability to clean and preprocess data, and select appropriate features for modeling\\n6. Understanding of model evaluation metrics and techniques for measuring performance\\n7. Familiarity with deep learning frameworks such as TensorFlow, PyTorch, or Keras\\n8. Strong problem-solving skills and critical thinking ability\\n9. Excellent communication skills to articulate findings and insights to non-technical stakeholders\\n10. Continuous learning mindset to stay updated with the latest trends and advancements in the field of machine learning.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = \"machine learning\"\n",
    "chain.invoke(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "llm_model = \"gpt-4-1106-preview\"\n",
    "llm = ChatOpenAI(temperature=0.5, model=llm_model)\n",
    "object = \"llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"what is the main skill to build {object}?\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"describe the  skills:{skills}?\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one,chain_two],verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mBuilding a language model like GPT (Generative Pre-trained Transformer) or any other large language model (LLM) involves a range of skills and expertise. Here are some of the main skills that are typically required:\n",
      "\n",
      "1. Machine Learning and Deep Learning: A strong understanding of machine learning principles and deep learning architectures, especially Transformer models, is crucial. This includes knowledge of how to structure neural networks, train them on large datasets, and optimize their performance.\n",
      "\n",
      "2. Natural Language Processing (NLP): Expertise in NLP is essential for understanding how to process and generate human-like text. This includes familiarity with tokenization, part-of-speech tagging, named entity recognition, sentiment analysis, and other NLP tasks.\n",
      "\n",
      "3. Programming: Proficiency in programming languages such as Python, which is commonly used for machine learning and data science tasks. Libraries like TensorFlow, PyTorch, Hugging Face Transformers, and others are important tools in the development of LLMs.\n",
      "\n",
      "4. Data Engineering: The ability to handle large datasets is crucial since LLMs require massive amounts of text data for training. Skills in data preprocessing, cleaning, and augmentation are necessary to ensure the quality of the training data.\n",
      "\n",
      "5. Distributed Computing: Training LLMs requires significant computational resources, often involving distributed computing across multiple GPUs or TPUs. Understanding how to parallelize and distribute the training process is important.\n",
      "\n",
      "6. Model Optimization: Knowledge of techniques to optimize model size and performance, such as quantization, pruning, knowledge distillation, and efficient attention mechanisms, can be very useful, especially when deploying models to production.\n",
      "\n",
      "7. Ethics and Bias Mitigation: Understanding the ethical implications of LLMs and how to address issues related to bias, fairness, and misuse is increasingly recognized as a critical skill in the field.\n",
      "\n",
      "8. Research Skills: Keeping up-to-date with the latest research, being able to read and understand scientific papers, and potentially contributing to the body of knowledge through original research are valuable skills for advancing the state of the art in LLMs.\n",
      "\n",
      "9. Team Collaboration: Developing an LLM is typically a team effort, involving collaboration among data scientists, machine learning engineers, software developers, and domain experts. Strong communication and teamwork skills are essential.\n",
      "\n",
      "10. Problem-Solving: Finally, a creative and analytical mindset is necessary to troubleshoot issues that arise during the development process and to innovate new solutions to improve model performance and capabilities.\n",
      "\n",
      "Building a large language model is a complex and multidisciplinary endeavor that requires a combination of the above skills. It's also an evolving field, so continuous learning and adaptation are key to staying current with the latest technologies and methodologies.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mBuilding a language model like GPT (Generative Pre-trained Transformer) or any other large language model (LLM) indeed involves a diverse set of skills. Here's a breakdown of the skills you mentioned, with additional context and insights:\n",
      "\n",
      "1. **Machine Learning and Deep Learning**: Understanding the theory behind machine learning algorithms, especially deep learning architectures like the Transformer, is fundamental. This includes knowing how to design and implement neural networks, as well as understanding backpropagation, regularization techniques, and different optimization strategies such as Adam or SGD.\n",
      "\n",
      "2. **Natural Language Processing (NLP)**: NLP expertise is critical for tasks like parsing, understanding, and generating human language. This includes a grasp of linguistic concepts such as syntax, semantics, and pragmatics, along with technical approaches like sequence modeling, context-aware embeddings, and attention mechanisms.\n",
      "\n",
      "3. **Programming**: Proficiency in programming, particularly in languages like Python, is essential. Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch) and libraries (e.g., NLTK, spaCy, Hugging Face's Transformers) enables the development and implementation of LLMs.\n",
      "\n",
      "4. **Data Engineering**: Since LLMs are data-hungry, the ability to work with big data is crucial. This involves skills in data collection, preprocessing, cleaning, and augmentation, as well as understanding how to structure and store data efficiently for training.\n",
      "\n",
      "5. **Distributed Computing**: Training LLMs typically requires high-performance computing resources. Knowledge of distributed systems, GPU/TPU programming, and cloud services (like AWS, GCP, or Azure) is important to manage the computational workload.\n",
      "\n",
      "6. **Model Optimization**: To make models more efficient, especially for deployment, one must be skilled in techniques like quantization (reducing the precision of the numbers used), pruning (removing weights or neurons with little impact), knowledge distillation (transferring knowledge from a large model to a smaller one), and designing efficient attention mechanisms.\n",
      "\n",
      "7. **Ethics and Bias Mitigation**: As AI models can perpetuate and amplify biases, it's important to understand these risks and implement strategies to mitigate bias. This involves ethical considerations in data handling, model design, and the broader implications of AI deployment.\n",
      "\n",
      "8. **Research Skills**: Keeping abreast of cutting-edge research is vital in this rapidly evolving field. The ability to read, understand, and critically evaluate research papers, as well as conduct original research, is key to pushing the boundaries of what LLMs can do.\n",
      "\n",
      "9. **Team Collaboration**: Building LLMs is a collaborative effort that often spans multiple roles and disciplines. Effective communication, project management, and the ability to work in interdisciplinary teams are important for the success of such projects.\n",
      "\n",
      "10. **Problem-Solving**: A problem-solving mindset is necessary to navigate the challenges that arise in model development. This includes debugging, experimenting, and innovating to overcome obstacles and improve model performance.\n",
      "\n",
      "In summary, constructing a large language model is an intricate task that requires a blend of technical expertise, creativity, and ethical consideration. Those involved in building LLMs must be adept learners and collaborators, ready to tackle complex problems and adapt to the rapid pace of advancements in the field.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'llm',\n",
       " 'output': \"Building a language model like GPT (Generative Pre-trained Transformer) or any other large language model (LLM) indeed involves a diverse set of skills. Here's a breakdown of the skills you mentioned, with additional context and insights:\\n\\n1. **Machine Learning and Deep Learning**: Understanding the theory behind machine learning algorithms, especially deep learning architectures like the Transformer, is fundamental. This includes knowing how to design and implement neural networks, as well as understanding backpropagation, regularization techniques, and different optimization strategies such as Adam or SGD.\\n\\n2. **Natural Language Processing (NLP)**: NLP expertise is critical for tasks like parsing, understanding, and generating human language. This includes a grasp of linguistic concepts such as syntax, semantics, and pragmatics, along with technical approaches like sequence modeling, context-aware embeddings, and attention mechanisms.\\n\\n3. **Programming**: Proficiency in programming, particularly in languages like Python, is essential. Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch) and libraries (e.g., NLTK, spaCy, Hugging Face's Transformers) enables the development and implementation of LLMs.\\n\\n4. **Data Engineering**: Since LLMs are data-hungry, the ability to work with big data is crucial. This involves skills in data collection, preprocessing, cleaning, and augmentation, as well as understanding how to structure and store data efficiently for training.\\n\\n5. **Distributed Computing**: Training LLMs typically requires high-performance computing resources. Knowledge of distributed systems, GPU/TPU programming, and cloud services (like AWS, GCP, or Azure) is important to manage the computational workload.\\n\\n6. **Model Optimization**: To make models more efficient, especially for deployment, one must be skilled in techniques like quantization (reducing the precision of the numbers used), pruning (removing weights or neurons with little impact), knowledge distillation (transferring knowledge from a large model to a smaller one), and designing efficient attention mechanisms.\\n\\n7. **Ethics and Bias Mitigation**: As AI models can perpetuate and amplify biases, it's important to understand these risks and implement strategies to mitigate bias. This involves ethical considerations in data handling, model design, and the broader implications of AI deployment.\\n\\n8. **Research Skills**: Keeping abreast of cutting-edge research is vital in this rapidly evolving field. The ability to read, understand, and critically evaluate research papers, as well as conduct original research, is key to pushing the boundaries of what LLMs can do.\\n\\n9. **Team Collaboration**: Building LLMs is a collaborative effort that often spans multiple roles and disciplines. Effective communication, project management, and the ability to work in interdisciplinary teams are important for the success of such projects.\\n\\n10. **Problem-Solving**: A problem-solving mindset is necessary to navigate the challenges that arise in model development. This includes debugging, experimenting, and innovating to overcome obstacles and improve model performance.\\n\\nIn summary, constructing a large language model is an intricate task that requires a blend of technical expertise, creativity, and ethical consideration. Those involved in building LLMs must be adept learners and collaborators, ready to tackle complex problems and adapt to the rapid pace of advancements in the field.\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.invoke(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "llm_model = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': ' Milk Frother Handheld\\n\\tI loved this product. But they only seem to l...',\n",
       " 'English_Review': 'Certainly! To provide a translation, I would need the full review text in the original language. The text you\\'ve provided \"I loved this product. But they only seem to l...\" is actually already in English but appears to be incomplete. Could you please provide the full review in the original language you would like translated?',\n",
       " 'summary': 'The review expresses love for the product but suggests that there may be limitations or issues concerning availability or variety.',\n",
       " 'followup_message': \"Thank you for taking the time to share your positive feedback about our product! We're thrilled to hear that you love it. We acknowledge the concerns you've mentioned regarding availability or variety, and we want to assure you that we are continuously working on improving our distribution processes and expanding our product range to better meet your needs and preferences. Your satisfaction is our top priority, and we hope to resolve these issues to enhance your experience with our brand. If you have any further suggestions or need assistance, please don't hesitate to reach out to us. Thank you for your support!\\n\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review =\" Milk Frother Handheld\\n\tI loved this product. But they only seem to l...\" \n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KshitijDilipSarve\\Desktop\\GENAI\\GENAI\\Lib\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! llm is not default parameter.\n",
      "                llm was transferred to model_kwargs.\n",
      "                Please confirm that llm is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import router\n",
    "llm_model = \"gpt-4-1106-preview\"\n",
    "llm = ChatOpenAI(temperature=0.5, llm=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'physics', 'description': 'Good for answering questions about physics', 'prompt_template': \"You are a very smart physics professor. You are great at answering questions about physics in a conciseand easy to understand manner. When you don't know the answer to a question you admitthat you don't know.\\n\\nHere is a question:\\n{input}\"}, {'name': 'math', 'description': 'Good for answering math questions', 'prompt_template': 'You are a very good mathematician. You are great at answering math questions. You are so good because you are able to break down hard problems into their component parts, \\nanswer the component parts, and then put them togetherto answer the broader question.\\n\\nHere is a question:\\n{input}'}, {'name': 'History', 'description': 'Good for answering history questions', 'prompt_template': 'You are a very good historian. You have an excellent knowledge of and understanding of people,events and contexts from a range of historical periods. You have the ability to think, reflect, debate, discuss and evaluate the past. You have a respect for historical evidenceand the ability to make use of it to support your explanations and judgements.\\n\\nHere is a question:\\n{input}'}, {'name': 'computer science', 'description': 'Good for answering computer science questions', 'prompt_template': ' You are a successful computer scientist.You have a passion for creativity, collaboration,forward-thinking, confidence, strong problem-solving capabilities,understanding of theories and algorithms, and excellent communication skills. You are great at answering coding questions. You are so good because you know how to solve a problem by describing the solution in imperative steps that a machine can easily interpret and you know how to choose a solution that has a good balance between time complexity and space complexity. \\n\\nHere is a question:\\n{input}'}]\n"
     ]
    }
   ],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]\n",
    "\n",
    "print(prompt_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: Good for answering questions about physics\n",
      "math: Good for answering math questions\n",
      "History: Good for answering history questions\n",
      "computer science: Good for answering computer science questions\n",
      "physics: Good for answering questions about physics\n",
      "math: Good for answering math questions\n",
      "History: Good for answering history questions\n",
      "computer science: Good for answering computer science questions\n",
      "physics: Good for answering questions about physics\n",
      "math: Good for answering math questions\n",
      "History: Good for answering history questions\n",
      "computer science: Good for answering computer science questions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(prompt_infos)\n",
    "print(destination_chains)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\KshitijDilipSarve\\AppData\\Local\\Temp\\ipykernel_15976\\2160379643.py:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n"
     ]
    }
   ],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is black body radiation?',\n",
       " 'text': \"Black body radiation refers to the pattern of electromagnetic radiation (light and heat) emitted by an object that absorbs all radiation incident upon it, at all wavelengths. Such an idealized object is called a black body, and it emits radiation solely based on its temperature, regardless of its shape or composition.\\n\\nThe spectrum of black body radiation is continuous and peaks at a wavelength that is inversely proportional to the temperature of the black body, as described by Wien's displacement law. The total energy emitted by a black body is related to the fourth power of its absolute temperature, a relationship known as the Stefan-Boltzmann law.\\n\\nBlack body radiation has a characteristic spectrum that shifts to shorter wavelengths as the temperature increases, meaning that hotter black bodies emit more radiation at shorter wavelengths. This phenomenon is why, for example, a heating element on a stove glows red as it gets hot, and the Sun, which is much hotter, emits a lot of visible and ultraviolet light.\\n\\nThe concept of black body radiation was crucial in the development of quantum mechanics. The classical physics of the time (late 19th century) could not explain the observed spectrum of black body radiation, which led to the ultraviolet catastrophe when using Rayleigh-Jeans law at short wavelengths. Max Planck resolved this by introducing the idea that energy is quantized, leading to Planck's law of black body radiation and the birth of quantum theory.\"}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is 30 + 44?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 30 + 44?',\n",
       " 'text': 'Thank you for the compliment! To answer your question:\\n\\n30 + 44 = 74\\n\\nThis is a simple addition problem where you add the two numbers together to get the sum.'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is 30 + 44?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GENAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
